import { NextRequest, NextResponse } from 'next/server'
import { createEnhancedRAGChain } from '@/lib/langchain/rag-chain'
import { AskRequest, AskResponse, Document } from '@/lib/types'
import { SettingsService } from '@/lib/settings-service'
import { ChatMessage } from '@/lib/chat-context'

export async function POST(request: NextRequest) {
  try {
    const body = await request.json()
    const { question, context }: { question: string; context?: ChatMessage[] } =
      body

    if (!question || typeof question !== 'string') {
      return NextResponse.json(
        { error: 'Question is required and must be a string' },
        { status: 400 }
      )
    }

    console.log('ü¶ú Using LangChain Enhanced RAG Chain for query:', question)

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    const contextEnabled = await SettingsService.getSetting('context_enabled')
    const contextEnabledValue = contextEnabled?.parameter_value === 'true'

    // –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    let finalQuery = question
    let hasContextInfo = false

    if (contextEnabledValue && context && context.length > 0) {
      console.log(`üìù –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ ${context.length} —Å–æ–æ–±—â–µ–Ω–∏–π`)

      // –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
      const contextString = context
        .map(
          (msg) =>
            `${msg.role === 'user' ? '–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å' : '–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç'}: ${
              msg.content
            }`
        )
        .join('\n')

      finalQuery = `–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞:
${contextString}

–¢–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å: ${question}

–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–≤–µ—Ç—å –Ω–∞ —Ç–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å, —É—á–∏—Ç—ã–≤–∞—è –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞. –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å —Å–≤—è–∑–∞–Ω —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏, –∏—Å–ø–æ–ª—å–∑—É–π —ç—Ç—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞.`

      hasContextInfo = true
    }

    // 1. Create enhanced RAG chain instance
    const ragChain = createEnhancedRAGChain()

    // 2. Process query through LangChain RAG pipeline
    let ragResult: {
      text: string
      sourceDocuments: any[]
      relevanceScores: number[]
    }

    let hasQdrantError = false

    try {
      console.log('üîç Processing query with LangChain RAG...')
      ragResult = await ragChain.call({ query: finalQuery })
      console.log(
        `üìä Found ${ragResult.sourceDocuments.length} relevant documents`
      )

      if (hasContextInfo) {
        console.log('‚úÖ –û—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞')
      }
    } catch (chainError) {
      console.error('‚ùå RAG Chain error:', chainError)
      hasQdrantError = true

      // Fallback to GPT-only response
      ragResult = {
        text: '–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å.',
        sourceDocuments: [],
        relevanceScores: [],
      }
    }

    // 3. Convert LangChain documents to our format for compatibility
    const sources: Document[] = ragResult.sourceDocuments.map((doc, index) => ({
      id: doc.metadata?.id || `doc_${index}`,
      content: doc.content || doc.pageContent || '',
      metadata: {
        ...doc.metadata,
        score: ragResult.relevanceScores[index] || doc.score || 0,
        relevanceScore: ragResult.relevanceScores[index] || doc.score || 0,
      },
    }))

    if (sources.length > 0) {
      console.log('üìù ‚úÖ LangChain RAG generated response with context')
    } else {
      if (hasQdrantError) {
        console.log('‚ö†Ô∏è Qdrant/LangChain unavailable, using fallback response')
      } else {
        console.log('‚ö†Ô∏è No relevant documents found, using GPT-only response')
      }
    }

    // 4. Format response to match existing API contract
    const response: AskResponse = {
      answer: ragResult.text,
      sources: sources.length > 0 ? sources : undefined,
      hasContext: sources.length > 0 || hasContextInfo, // –£—á–∏—Ç—ã–≤–∞–µ–º –∏ RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
      sourcesCount: sources.length,
      searchScore:
        sources.length > 0
          ? Math.max(...ragResult.relevanceScores, 0.85) // Higher score due to LangChain enhancement
          : undefined,
      qdrantStatus: hasQdrantError ? 'error' : 'ok',
    }

    console.log('üéâ LangChain RAG response ready:', {
      hasContext: response.hasContext,
      sourcesCount: response.sourcesCount,
      answerLength: response.answer.length,
    })

    return NextResponse.json(response)
  } catch (error) {
    console.error('‚ùå Error in /api/ask (LangChain):', error)

    // Enhanced error handling for LangChain specific issues
    if (error instanceof Error) {
      if (
        error.message.includes('QDRANT_URL') ||
        error.message.includes('vector store')
      ) {
        return NextResponse.json(
          {
            error: 'Vector database is not configured. Please set up Qdrant.',
            details: 'LangChain Qdrant connection failed',
          },
          { status: 503 }
        )
      }

      if (error.message.includes('OPENAI_API_KEY')) {
        return NextResponse.json(
          {
            error: 'OpenAI API key is not configured.',
            details: 'LangChain OpenAI connection failed',
          },
          { status: 503 }
        )
      }
    }

    return NextResponse.json(
      {
        error: 'Internal server error',
        details: 'LangChain RAG pipeline failed',
      },
      { status: 500 }
    )
  }
}
