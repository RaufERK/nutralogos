import { NextRequest, NextResponse } from 'next/server'
import { createEnhancedRAGChain } from '@/lib/langchain/rag-chain'
import { createStreamingLLM } from '@/lib/langchain/llm'
import { Document } from '@/lib/types'
import { SettingsService } from '@/lib/settings-service'
import { ChatMessage } from '@/lib/chat-context'
import {
  createDynamicPrompt,
  formatEnhancedContextForPrompt,
} from '@/lib/langchain/prompts'
import { RAGSettings } from '@/lib/settings-service'

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π —á–µ—Ä–µ–∑ WebSocket HTTP bridge
type OutboundMessage =
  | { type: 'start'; messageId: string; question: string }
  | {
      type: 'sources'
      messageId: string
      sources: Array<{
        id: string
        content: string
        metadata?: Record<string, unknown>
        score?: number
        relevanceScore?: number
      }>
    }
  | { type: 'chunk'; messageId: string; content: string }
  | { type: 'complete'; messageId: string }
  | { type: 'error'; messageId: string; error: string }

async function sendToClient(
  clientId: string,
  message: OutboundMessage
): Promise<boolean> {
  try {
    const httpPort = process.env.WEBSOCKET_HTTP_PORT || '3002'
    const baseUrl =
      process.env.WEBSOCKET_HTTP_URL || `http://localhost:${httpPort}`
    const response = await fetch(`${baseUrl}/send-message`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        clientId,
        message,
      }),
    })

    if (!response.ok) {
      console.error(
        '‚ùå HTTP bridge error:',
        response.status,
        response.statusText
      )
      return false
    }

    return true
  } catch (error) {
    console.error('‚ùå Failed to send WebSocket message:', error)
    return false
  }
}

export async function POST(request: NextRequest) {
  try {
    const body = await request.json()
    const {
      question,
      context,
      clientId,
      messageId,
    }: {
      question: string
      context?: ChatMessage[]
      clientId: string
      messageId: string
    } = body

    if (!question || typeof question !== 'string') {
      return NextResponse.json(
        { error: 'Question is required and must be a string' },
        { status: 400 }
      )
    }

    if (!clientId || !messageId) {
      return NextResponse.json(
        { error: 'ClientId and messageId are required for streaming' },
        { status: 400 }
      )
    }

    console.log('üîÑ Starting streaming RAG for query:', question)
    console.log('üì° Client ID:', clientId, 'Message ID:', messageId)

    // –£–≤–µ–¥–æ–º–ª—è–µ–º –∫–ª–∏–µ–Ω—Ç–∞ –æ –Ω–∞—á–∞–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    await sendToClient(clientId, {
      type: 'start',
      messageId,
      question,
    })

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    const contextEnabled = await SettingsService.getSetting('context_enabled')
    const contextEnabledValue = contextEnabled?.parameter_value === 'true'

    // –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    let finalQuery = question
    let hasContextInfo = false

    if (contextEnabledValue && context && context.length > 0) {
      console.log(`üìù –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ ${context.length} —Å–æ–æ–±—â–µ–Ω–∏–π`)

      const contextString = context
        .map(
          (msg) =>
            `${msg.role === 'user' ? '–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å' : '–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç'}: ${
              msg.content
            }`
        )
        .join('\n')

      finalQuery = `–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞:
${contextString}

–¢–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å: ${question}

–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–≤–µ—Ç—å –Ω–∞ —Ç–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å, —É—á–∏—Ç—ã–≤–∞—è –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞. –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å —Å–≤—è–∑–∞–Ω —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏, –∏—Å–ø–æ–ª—å–∑—É–π —ç—Ç—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞.`

      hasContextInfo = true
    }

    // –°–æ–∑–¥–∞–µ–º RAG chain –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    const ragChain = createEnhancedRAGChain()

    let sources: Document[] = []
    let hasQdrantError = false

    try {
      console.log('üîç –í—ã–ø–æ–ª–Ω—è–µ–º RAG –ø–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...')

      // RAG –ø–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

      // –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (—ç—Ç–æ –±—ã—Å—Ç—Ä–æ, –¥–µ–ª–∞–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ)
      const ragResult = await ragChain.call({ query: finalQuery })

      // –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –Ω–∞—à —Ñ–æ—Ä–º–∞—Ç
      sources = ragResult.sourceDocuments.map((doc, index) => ({
        id: String(doc.metadata?.id || `doc_${index}`),
        content: doc.content || doc.pageContent || '',
        metadata: {
          ...doc.metadata,
          score: ragResult.relevanceScores[index] || doc.score || 0,
          relevanceScore: ragResult.relevanceScores[index] || doc.score || 0,
        },
      }))

      console.log(`üìä –ù–∞–π–¥–µ–Ω–æ ${sources.length} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤`)

      // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∫–ª–∏–µ–Ω—Ç—É
      if (sources.length > 0) {
        await sendToClient(clientId, {
          type: 'sources',
          messageId,
          sources: sources.map((s) => ({
            id: String(s.id),
            content: s.content,
            metadata: s.metadata as Record<string, unknown>,
            score: s.metadata?.score,
            relevanceScore: s.metadata?.relevanceScore,
          })),
        })
      }
    } catch (chainError) {
      console.error('‚ùå RAG Chain error:', chainError)
      hasQdrantError = true
      console.log('üîÑ Continuing with GPT-only mode for streaming...')

      // –ù–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—à–∏–±–∫—É –∫–ª–∏–µ–Ω—Ç—É, –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ RAG
      sources = []
    }

    // –°–æ–∑–¥–∞–µ–º streaming LLM
    const streamingLLM = await createStreamingLLM()

    // –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–º–ø—Ç
    const spiritualEnabled = await RAGSettings.isSpiritualPromptEnabled()
    const prompt = await createDynamicPrompt(spiritualEnabled)

    // –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
    const context_text =
      sources.length > 0
        ? formatEnhancedContextForPrompt(
            sources.map((s) => ({
              pageContent: s.content,
              metadata: s.metadata as unknown as Record<string, unknown>,
            }))
          )
        : '–ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω.'

    // –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç
    const formattedPrompt = await prompt.format({
      context: context_text,
      question: finalQuery,
    })

    console.log('ü§ñ –ù–∞—á–∏–Ω–∞–µ–º streaming –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –æ—Ç–≤–µ—Ç–∞...')

    try {
      // –ó–∞–ø—É—Å–∫–∞–µ–º streaming –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
      const stream = await streamingLLM.stream([
        {
          role: 'system',
          content: formattedPrompt,
        },
      ])

      // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —á–∞–Ω–∫
      for await (const chunk of stream as AsyncIterable<{
        content?: unknown
      }>) {
        const raw = (chunk as { content?: unknown }).content
        const content =
          typeof raw === 'string'
            ? raw
            : Array.isArray(raw)
            ? (raw as Array<unknown>)
                .map((c) =>
                  typeof c === 'string'
                    ? c
                    : typeof c === 'object' && c && 'text' in c
                    ? String((c as { text?: unknown }).text || '')
                    : ''
                )
                .join('')
            : String(raw ?? '')
        if (content) {
          // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —á–∞–Ω–∫ –∫–ª–∏–µ–Ω—Ç—É
          await sendToClient(clientId, {
            type: 'chunk',
            messageId,
            content,
          })
        }
      }

      console.log('‚úÖ Streaming –∑–∞–≤–µ—Ä—à–µ–Ω, –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω')

      // –£–≤–µ–¥–æ–º–ª—è–µ–º –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏
      await sendToClient(clientId, {
        type: 'complete',
        messageId,
      })

      // –í–æ–∑–≤—Ä–∞—â–∞–µ–º —É—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç
      return NextResponse.json({
        success: true,
        messageId,
        hasContext: sources.length > 0 || hasContextInfo,
        sourcesCount: sources.length,
        qdrantStatus: hasQdrantError ? 'error' : 'ok',
      })
    } catch (streamingError) {
      console.error('‚ùå Streaming error:', streamingError)

      // –£–≤–µ–¥–æ–º–ª—è–µ–º –∫–ª–∏–µ–Ω—Ç–∞ –æ–± –æ—à–∏–±–∫–µ
      await sendToClient(clientId, {
        type: 'error',
        messageId,
        error: '–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞',
      })

      return NextResponse.json(
        {
          error: 'Streaming generation failed',
          details:
            streamingError instanceof Error
              ? streamingError.message
              : 'Unknown error',
        },
        { status: 500 }
      )
    }
  } catch (error) {
    console.error('‚ùå Error in /api/ask-stream:', error)

    // Enhanced error handling
    if (error instanceof Error) {
      if (
        error.message.includes('QDRANT_URL') ||
        error.message.includes('vector store')
      ) {
        return NextResponse.json(
          {
            error: 'Vector database is not configured. Please set up Qdrant.',
            details: 'Qdrant connection failed',
          },
          { status: 503 }
        )
      }

      if (error.message.includes('OPENAI_API_KEY')) {
        return NextResponse.json(
          {
            error: 'OpenAI API key is not configured.',
            details: 'OpenAI connection failed',
          },
          { status: 503 }
        )
      }
    }

    return NextResponse.json(
      {
        error: 'Internal server error',
        details: 'Streaming RAG pipeline failed',
      },
      { status: 500 }
    )
  }
}

export const runtime = 'nodejs'
